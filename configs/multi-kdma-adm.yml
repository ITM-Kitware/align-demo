chat_kdma_predicting_adm:
  language_model:
    device: cuda:1
    model_name: meta-llama/Llama-2-7b-chat-hf
    precision: full

  predict_outcomes:
    template: pred_outcome.txt
    max_new_tokens: 512
    temperature: 0.6

  predict_kdma_values:
    template: pred_kdma_RO.txt
    kdma_descriptions_file: lib/templates/bbn_kdma_descriptions.yml
    generate_reasoning: True
    max_new_tokens: 512
    temperature: 0.6